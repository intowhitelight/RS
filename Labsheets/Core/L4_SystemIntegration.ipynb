{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNkIAJM9vNOEKhFzHMDOn9Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulodowd/EMATM0054_53/blob/main/L4_SystemIntegration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labsheet 4: System Integration\n"
      ],
      "metadata": {
        "id": "9jIhnaooykXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This labsheet will help you to bring the components of your solution together, and to think about the higher-level tasks that your 3Pi+ robot must be programmed to complete."
      ],
      "metadata": {
        "id": "l0IwTNwryo2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br><br><br><br>\n"
      ],
      "metadata": {
        "id": "Q1YGalchzP2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finite State Machine (FSM)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/theory.png\" align=\"left\"> The below illustration is a state diagram for a solution to Assessment 1.  It is regarded as a finite state machine because it should capture all possible states and transitions that the system will operate.Whilst you may not have all parts of the problem solved yet, it is good to look ahead and think about the structure of your code.  \n",
        "\n"
      ],
      "metadata": {
        "id": "kGNSf_VRGvLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/fsm.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "qTCg-mQXFy0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we review the above diagram, we can regard each state as a `robot behaviour`.  In particular, it is important to note:\n",
        "- Most states loop back into themselves.  For example, the `calibration` transitions back into `calibration` whilst the robot has not completed `2 rotations`.  `return to start area` loops back into `return to start area` whilst the robot has not reached the start area.\n",
        "  - This principle should be reflected in the functions you have been recommended to write that are **non-blocking**.  Therefore, whilst your code is within a particular state, it should be able to repeatedly call the same **non-blocking** function.\n",
        "  - Each state (or behaviour) is therefore checking for conditions to transition to other states.\n",
        "  - You can write your code so that this **state transition** is either managed by each state itself, or a section of code at the beginning of `loop()` can determine the correct state on each iteration.\n",
        "- Some states represented may in fact be more complicated than shown.  In fact, a state like `search area` may itself have a state machine.  \n",
        "  - For example, in the Assessment 1 Video Submission example, the 3Pi+ robot can be observed to stay within the search area marked by a grid.  Therefore, within the state `search area`, there is a detection of the robot position operating to keep the robot on the right hand portion of the coursework map."
      ],
      "metadata": {
        "id": "FDAVsjYrIMTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can therefore quickly illustrate a general code structure that would enable for your code to be organised as a finite state machine:\n",
        "\n",
        "```c\n",
        "\n",
        "#define STATE_CALIBRATE   0  // give each behaviour a number\n",
        "#define STATE_LEAVE_START 1\n",
        "#define STATE_SEARCH_AREA 2\n",
        "int state;                  // this will track which state is active\n",
        "\n",
        "void setup() {\n",
        "\n",
        "  // Which state should the robot start in?\n",
        "  state = STATE_CALIBRATE;\n",
        "\n",
        "}\n",
        "\n",
        "void loop() {\n",
        "\n",
        "  // Update FSM.  Check which state we are currently\n",
        "  // in.  States will transition themselves.\n",
        "  if( state == STATE_CALIBRATE ) {\n",
        "\n",
        "    // call calibration routine (non-blocking)\n",
        "    doCalibration();\n",
        "\n",
        "    // Should we move to the next state?\n",
        "    if( ???? >  ???? ) {\n",
        "\n",
        "      // move the state variable to next state\n",
        "      state = STATE_LEAVE_START;\n",
        "\n",
        "      // Prepare any variables or functions\n",
        "      setForwards( 2000 );\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "  } else if( state == STATE_LEAVE_START ) {\n",
        "\n",
        "    // Finished moving forwards? (non-blocking)\n",
        "    bool status = checkForwards();\n",
        "    \n",
        "    // Should we move to next state?\n",
        "    if( status == false ) {\n",
        "      \n",
        "      // move the state variable to next state\n",
        "      state = STATE_SEARCH_AREA;\n",
        "\n",
        "      // Prepare any functions or variables\n",
        "      // ...\n",
        "    }\n",
        "\n",
        "\n",
        "  } else if( state == STATE_SEARCH_AREA ) {\n",
        "\n",
        "      // continue search (non-blocking)\n",
        "      checkSearch();\n",
        "\n",
        "      // Should we move to next state?\n",
        "      if( ???? > ???? ) {\n",
        "\n",
        "        // move the state variable to next state\n",
        "        state = ????;\n",
        "\n",
        "      } else if ( ???? > ???? ) {\n",
        "\n",
        "        // You can also branch which state is next\n",
        "        state = ????;\n",
        "        \n",
        "      }\n",
        "\n",
        "  } // End of FSM update\n",
        "\n",
        "} // End of loop()\n",
        "\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "hxsjTexoIo03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: Build a Finite State Machine (FSM)\n",
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/exercise.png\" align=\"left\">  **Exercise:** Take the time to refactor your code to fit into a FSM framework, such as the extract above.  \n"
      ],
      "metadata": {
        "id": "pmb2Qd0YywpL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/tick.png\" align=\"left\"> Organising your code into a FSM has several advantages.  The most important concerns debugging.  With a FSM, you can enable and disable parts of your code by simply changing the state transitions, or commenting out state transitions, or even over-riding the state at the top of `loop()` (for example, by setting `state = STATE_DEBUG;` as the first thing in `loop()`, the `if()` statement would always select the code for `state == STATE_DEBUG`).  "
      ],
      "metadata": {
        "id": "vfitdBkfKhw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/tick.png\" align=\"left\"> When you are working towards the final solution for Assessment 1, your solution will have grown in size and complexity.  If it takes 3 minutes to watch your robot operate, you could waste a lot of time.  For example, if you are debugging **return to start area**, it is not strictly necessary to observe the whole solution.  Instead, you can set the robot to begin in the state to \"return to start\", and start the kinematics from any position to test (e.g. `pose.initialise( 100, -300, 0);`).  This way, you avoid having to watch the robot slowly search for a magnet, etc.  With a FSM, once you have finished debugging, you can easily return your code back to full functionality."
      ],
      "metadata": {
        "id": "zc3EY19RK-uR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br><br><br><br>"
      ],
      "metadata": {
        "id": "G79pOev9Xohp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High Level Movement Routines (Kinematics)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/theory.png\" align=\"left\">  To complete Assessment 1 fully, your robot is required to make two movements that require information on the position of the robot with respect to where it started.  These are:\n"
      ],
      "metadata": {
        "id": "vsnO2bg9yz_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Returning to the start area.\n",
        "- Returning to the magnet location.\n",
        "\n",
        "In the following exercises, we will first ensure that the robot can estimate it's pose, and then adapt previous movement routines to utilise pose information.\n",
        "\n",
        "The <a href=\"https://github.com/paulodowd/EMATM0054_53/tree/main/3Pi_CodeStub\">code stub</a> that has been provided to you has a complete class for kinematics (`Kinematics.h`).  The kinematics is the mathematics to estimate the robot location based on the number of encoder counts that have occured.  This technique is known as **dead reckoning**, a form of **odometry**.  \n",
        "\n",
        "**Odometry** is a more general term and means to use sensors to estimate a change of position over time.  This could include sensors such as gyroscopes, accelerometers, etc - which are not covered in these labsheets.  \n",
        "\n",
        "**Dead-reckoning** is a more specific term, which informally means to attempt to \"keep count\" relative to a previously known or fixed position.  Our robot has a known starting position - the location where it is activated (powered on), which we can consider to mean $x_{I}=0$, $Y_{I}=0$ and $\\theta_{I}=0$, where the subscript `I` means \"global frame\".  We can understand \"global frame\" to mean, a position relative to where the robot started.  \n",
        "\n",
        "To do this, you need to ensure that your code for your 3Pi+ robot has the following essential lines of code (with the rest removed here):\n",
        "\n",
        "```c\n",
        "#include \"Encoders.h\"   // provide automatic counting of encoders\n",
        "#include \"Kinematics.h\" // maths for odometry/dead-reckoning\n",
        "\n",
        "// Create a global instance of the kinematics class\n",
        "Kinematics_c pose;\n",
        "\n",
        "void setup() {\n",
        "\n",
        "  // Initialises the routines that will automatically\n",
        "  // count the rotations of the wheels.\n",
        "  setupEncoder0();\n",
        "  setupEncoder1();\n",
        "\n",
        "  // Initialise the pose of the robot to x=0, y=0,\n",
        "  // theta=0.  \n",
        "  pose.initialise( 0, 0, 0 );\n",
        "\n",
        "}\n",
        "\n",
        "void loop() {\n",
        "\n",
        "  // Instruct the kinematics to perform an update\n",
        "  // of the robot position\n",
        "  // It is recommended you schedule this to occur at\n",
        "  // a fixed interval, such as 20ms.\n",
        "  pose.update();\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nHsOUYhwBRAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2: Calibrate the Kinematics\n",
        "\n",
        "The kinematics provided to you has the measurements provided by the manufacturer as the model parameters.  These parameters can be improved by conducting a manual calibration.  Unlike previous calibration exercises, this cailbration is not expected to be automatic or autonomous.  Instead, we will need to produce some simple movements with the robot and inspect the outcomes."
      ],
      "metadata": {
        "id": "2JwVn6XT4NaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/exercise.png\" align=\"left\">  **Exercise:** We will test that the `Kinematics_c` class is working correctly, and then follow some steps to calibrate the parameters of the kinematics.  Incorporate the above code extract into code that operates your 3Pi+ robot.  You can either start a new sketch to keep things simple (recommended), or attempt to integrate the above essential lines of code into your current program.  If you are using an existing program, you will want to disable all behaviours/operations whilst we work to calibrate the kinematics (e.g., we do not want the robot to try to move).\n",
        "\n"
      ],
      "metadata": {
        "id": "QDB7zlbA5A7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Ensure that `pose.update();` is being called within `loop()`. It is highly recommended that you schedule this function call using `millis()` to operate at an interval such as 20ms.  This technique was originally covered in Labsheet 0.\n",
        "\n",
        "2. Test that your program is updating values within the kinematics class by using Serial.print() on the variables `pose.x`, `pose.y`, `pose.theta`.  \n",
        "  - Add these print statments into `loop()`.\n",
        "  - Remember that you can increase the precision of `Serial.print()` by adding a whole number as a second argument, e.g. `Serial.print( pose.x, 4 );`\n"
      ],
      "metadata": {
        "id": "yLTa2qjT5c4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. **Calibrating Translation**: The coursework map has a grid with 10mm spacing between cells drawn in light grey.  Use this to calibrate the **x contribution** (forward translation) of your robot.  \n",
        "  - Position your robot with the axles of both wheels aligned over the line marked 0mm.  \n",
        "  - **Without motor power**, push the robot along in a straight line, stopping at the line marked 100mm.\n",
        "  - Inspect the output for the **x coordinate** from the pose instance of `Kinematics_c`.  You can do this simply with `Serial.print( pose.x, 4 );`.\n",
        "  - If your x coordinate is more than 100mm, you will need to reduce the parameter `wheel_radius` in the file `Kinematics.h`.\n",
        "  - If your x coordinate is less than 100mm, you will need to increase the parameter `wheel_radius` in the file `Kinematics.h`.\n",
        "  - Repeat this process improving the reported value of X."
      ],
      "metadata": {
        "id": "F8G4KwOK8LIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "<img width=\"250px\" src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/3Pi_grid_start.jpg\"> &nbsp; <img width=\"250px\" src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/3Pi_grid_end.jpg\"><br>\n",
        "<small>The robot positioned at the start of the grid, with the wheel axle positioned over the line 0mm (left).  The robot at the end of the grid, with the wheel axle positioned over the line marked 100mm (right).\n",
        "</p>"
      ],
      "metadata": {
        "id": "ApJQ06Pz7mcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Calibrating Rotation:** The coursework map has a radial figure of angles in radians.  Use this to calibrate the rotation (**theta contribution**) of your robot.\n",
        "  - Position the robot exactly within the centre of the radial figure.  You can do this by lining up the wheel axles with a horizontal line, and by lining up the gap between the bumper levers with the vertical line.  \n",
        "  - **Without motor power** rotate the robot to a pre-determined angle, such as 90 degrees ($\\frac{\\pi}{2}$).\n",
        "  - Inspect the reported value of `theta`.  \n",
        "  - Increase or decrease the parameter `wheel_sep` (wheel seperation) within `Kinematics.h` depending on whether the reported value is too high or too low."
      ],
      "metadata": {
        "id": "aKDgBGmF5AIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/hypothesis.png\" align=\"left\">**Hypothesise:** Following these instructions, we have calibrated translation before rotation.  Why might the order of calibrating these be important?"
      ],
      "metadata": {
        "id": "7FUF5Btv9pYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/hypothesis.png\" align=\"left\">**Hypothesise:** The <a href=\"https://www.pololu.com/product/4975/resources\">manufacturer documentation</a> for the Pololu 3Pi+ is quite detailed and includes important measurements for the robot.  Why might the reported measurements be inaccurate? What factors may influence the effect of these parameters on the kinematic model?"
      ],
      "metadata": {
        "id": "PuHHQOtv9vWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/info.png\" align=\"left\">  The kinematic model provided in `Kinematics.h` is a simpler form which assumes that the robot will either translate or rotate (exclusively).  The kinematics model movement as a translation, followed by a rotation.  Therefore, the model will represent curved motion as a straight-line approximation.  Some error is inherent to the model.  However, the simple kinematic model has proven sufficient to complete Assessment 1 to a high standard."
      ],
      "metadata": {
        "id": "UZaBmaY5-71D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/hypothesis.png\" align=\"left\">**Hypothesise:** It would make sense that calling `pose.update()` as quickly as possible would reduce the error of a straight-line approximation of a curve (the curve would be represented by smaller segments, a \"higher resolution\").  However, this does not seem to be the case in reality.  Why might this be?"
      ],
      "metadata": {
        "id": "TSVdGg4eAk7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/info.png\" align=\"left\">  If you would like more information on the kinematic model, a good source of further reading is the book: **Siegwart, R., Nourbakhsh, I.R., Scaramuzza, D., Arkin, R.C. (2011) Introduction to Autonomous Mobile Robots 2nd Edition.  MIT Press. ISBN-10 0262015358.** (<a href=\"https://bris.on.worldcat.org/oclc/708414202\">available in the University of Bristol Library</a>)"
      ],
      "metadata": {
        "id": "SEbR-mX1-LwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br><br><br><br>\n"
      ],
      "metadata": {
        "id": "KEQvBydaCRVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: Turning a Precise Angle\n",
        "\n",
        "In previous labsheets, you have been guided towards writing a **non-blocking** function to perform forwards travel, turning, or both - with a duration specified in milliseconds (_ms_).  You may have found values of PWM and duration to create a turn of 90 degrees, for example.  A clear issue with this approach is that it is **open-loop**, meaning that the robot does not know if it has achieved the desired turn, and the performance may vary between robots, or within the robot's operational lifetime.  This can lead to a lot of frustration, where we feel that the robot \"should\" turn 90 degrees - but of course there is no reason it \"should\".\n",
        "\n",
        "With the kinematic model, we can now instruct the robot to perform a turn to face a desired angle.  This means duration is no longer required, the robot can manage the turn operation until the angle is achieved - **closed-loop control**.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9XA3d7lXAXvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/3Pi_DiffAngles.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "nvIvkqJaGScV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above illustrations we see 3 different rotations of the 3Pi+ robot with respect to the global coordinate frame ($X_{I}$, $Y_{I}$).  The blue arrow represents the robots current rotation, $\\theta_{I}$ (`pose.theta`).  The green arrow represents a desired target angle.  \n",
        "\n",
        "In the first panel, the problem appears easy.  $\\theta_{I}$ is zero, and the robot will rotate positively towards the green arrow.  If the green arrow was $45°$, then $45 > 0$ (i.e. target > $\\theta_{I}$), and we could take this to mean rotate left.\n",
        "\n",
        "In the second panel, we can imagine that $\\theta_{I}$ is now 350°, and the green arrow (target angle) is 10°.  Now, 10° < 350° (i.e. target < $\\theta_{I}$, **less than!**), and so the robot would rotate **right** - the long way around.\n",
        "\n",
        "Therefore, when we consider this problem, we can articulate it as **requiring the smallest angle between two angles**.  Let's call \"the smallest angle between two angles\" $\\theta_{s}$.  To produce an effective turning behaviour, we therefore want to:\n",
        "- work out the current value of $\\theta_{s}$, for the current rotation $\\theta_{I}$ and the desired angle.\n",
        "- rotate in the right direction to make the next calculation of $\\theta_{s}$ smaller (minimisation problem)\n",
        "- stop moving once $\\theta_{s} = 0 $ (the target has been reached)."
      ],
      "metadata": {
        "id": "Nzz-uVkcGcSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/exercise.png\" align=\"left\">  **Exercise:** Using the **non-blocking** functions you have previously written for your robot movement, update them so that `setTurn()` (or whatever you called it) now takes a `float` argument for the `target_angle`.  Update your `checkTurn()` function (or whatever you called it) to now check if $\\theta_{s}$ has reached a near zero value.  If it has, the robot should stop.  If it has not, the robot should continue turning in the correct direction.\n",
        "- Add a global variable that represents `target_angle`.  Whilst we could change this value directly from anywhere in the code, this could lead to many debugging problems.  Instead, use the function `setTurn()` to set the value. This way, the turn operation will be standardised and consistent.  You will want to call `setTurn()` once, when the turn operation is first required. After this, you will want to call `checkTurn()` to complete the turn in a non-blocking way.\n",
        "- It is recommended you only update your kinematics at one location in your code, to keep the execution of your code as predictable and as consistent as possible.  A good location is therefore within `loop()`, because we will want to update the kinematics on every iteration of `loop()`.  Therefore, it is not necessary to call `pose.update()` within your turning functions.\n",
        "- Remember that the kinematics class (`Kinematics_c`) instance `pose` is defined as a global variable.  Therefore, your functions `setTurn()` and `checkTurn()` can access the instance `pose.` easily.\n",
        "- The issue of two angles crossing the 0/360 axis of a circle is a well understood problem.  The <a href=\"https://en.wikipedia.org/wiki/Atan2\">atan2</a> function helps significantly in solving this problem.\n",
        "- Stopping precisely can be difficult.  Once you have a calculation for $\\theta_{s}$, use an `if()` statement to check if this has reached a small enough value.  For example:\n",
        "\n",
        "```c\n",
        "// You can define a value at the top of your program\n",
        "// so that you don't have to search for it when you\n",
        "// want to change it.\n",
        "#define TURN_THRESHOLD 0.1\n",
        "\n",
        "bool checkTurn() {\n",
        "\n",
        "  // Is the difference between current rotation and\n",
        "  // target_angle now sufficiently small?\n",
        "  // Function abs() returns the unsigned value.\n",
        "  if( abs(angle_difference) < TURN_THRESHOLD ) {\n",
        "\n",
        "    // Stop robot\n",
        "    motors.setPWM( 0, 0 );\n",
        "\n",
        "    // Signal turn complete.\n",
        "    return true;\n",
        "\n",
        "  }\n",
        "\n",
        "  // Signal turn has not finished.\n",
        "  return false;\n",
        "\n",
        "} // End of checkTurn()\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "QJ4oA-6QCWIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/validate.png\" align=\"left\"> **Validate:** validate that your turning operation is working by trying various test cases.  It is likely that you cannot know in advance what rotation your robot will have when it must complete a turn towards a target angle.  Remember that you can be more efficient in your debugging by isolating parts of your code.  For example, it will cost a lot of time if you have to watch your robot peform line sensor and magnetometer calibrations every time you activate it."
      ],
      "metadata": {
        "id": "ZbUCgpa_Q6Ht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/info.png\" align=\"left\"> If you have completed the Advanced Exercises for Labsheet 1, you can improve this turn operation further.  It is possible to implement a PI-Controller that takes $\\theta_{s}$ (the smallest difference between two angles) and produces as output a speed demand (in encoder counts per ms, or mm/ms).  Remember that a PID is really mapping an input to an output, and it is essentially unit-agnostic.  This speed demand output is then feed as an input into the PI-Controllers for wheel speeds.  This is referred to as **nested PID control**, where one PID controller is manipulating another PID controller.  The advantage of this is that your robot will be able to move very slowly, and close very small gaps in rotation to face a precise angle."
      ],
      "metadata": {
        "id": "crxKE2mJM3Cf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br><br><br><br>"
      ],
      "metadata": {
        "id": "RiVxkXshMdiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4: Travelling to X,Y Coordinates.\n",
        "\n",
        "In the previous exercise you completed code to allow your robot to rotate to face a specified angle.  This is a key component to travelling to a target X and Y location.  We can consider travelling to an X,Y coordinate as having two discrete steps:\n",
        "- Rotate to face the target.\n",
        "- Move forwards until the distance is to the target X,Y coordinate is 0.\n",
        "\n",
        "If these steps are not seperated initially, your robot will produce a very large turn, like so:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"400px\" src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/3Pi_LongTurn.png\" >\n",
        "</p>\n",
        "\n",
        "However, it is **advantageous** if your robot corrects for error in rotation whilst it travels after the initial rotation.  \n"
      ],
      "metadata": {
        "id": "hBv6nwO1MeHW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/stop.png\" align=\"left\"> The main issue with the above behaviour is that it is a **requirement of Assessment 1** that your robot takes the **shortest path** back to the start area, and the **shortest path** back to the magnet location.  Therefore, a large looping movement is in breach of this requirement.  Some deviation is acceptable, as long as it is clear that your robot is attempting the shortest path."
      ],
      "metadata": {
        "id": "RGYfU62KQNZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/info.png\" align=\"left\"> **Information:** There are a few other issues with the above movement.  First, it could send your robot outside the coursework map area, which would be in breach of the requirements for Assessment 1.  Second, to minimise error in kinematics, you will also want to be relatively efficient with the types of movement your robot produces."
      ],
      "metadata": {
        "id": "Z-3Ydx-BQa6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/exercise.png\" align=\"left\">  **Exercise:** For this exercise, program your robot to begin at some non-zero coordinates for $X_{I}$ and $Y_{I}$.  We will focus on getting the robot to travel back to the origin.  You may want to first discover a set of test coordinates somewhere on the coursework map by simply pushing your robot to the location whilst it prints `pose.x` and `pose.y`."
      ],
      "metadata": {
        "id": "bs7Atw-QUqAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reviewing the below illustration, there will be **two angles** that we are concerned with:\n",
        "- The angle from the robot location to the origin, marked $\\theta_{H}$ ('H' for home).\n",
        "- The current rotation of the robot with respect to the global frame, $\\theta_{I}$.\n",
        "\n",
        "This presents two angles, a similar condition to the previous exercise (\"Turning a Precise Angle\")."
      ],
      "metadata": {
        "id": "NSs3vDCqWOni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "<img width=\"500px\" src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/3Pi_GoingHome.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "FhdElUTzT_Az"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Manipulate $\\theta_{H}$ so that we understand the angle required from the robot's point of view.  E.g., looking from the robot back towards the origin.\n",
        "2. Call your set of turn functions, and test that your robot can rotate to face the origin.  \n",
        "  - Test this from different positions on the coursework map."
      ],
      "metadata": {
        "id": "h6LKytv_WyMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br><br><br><br>\n"
      ],
      "metadata": {
        "id": "u1ENVBF_zQx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search Routines\n",
        "\n",
        "The final part of improving your solution may revolve around the choices you make on the search routine to find the magnet.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/hypothesis.png\" align=\"left\">**Hypothesise:** If kinematic error is accumulating, what would and when we expect to observe the effect?  How could we measure this?  We know that the kinematics (dead-reckoning) will have some degree of error in the estimation of the robot position.  Furthermore, the quantity of error will be effected by factors such as **(a)** the total time spent moving **(b)** any asymmetry in movement **(c)** external factors, such as wheel slip, **(d)** any substantial `delay()` in your code, **(etc)**.  Therefore, it is worthwhile attempting to observe, theorise and predict on an optimal search routine to minimise some of those factors.  "
      ],
      "metadata": {
        "id": "ZiOOu1P5LhVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/Search_Good_Bad.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "Ccw1uOnYh6YP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/observation.png\" align=\"left\"> **Observations:** Regarding the above, the first observation we can make is that only half of the coursework map will be the area of interest.  This is because the magnet will be placed into the green area (righthand side).  Therefore, we can improve the overall chance of success, and potentially the time spent travelling, by only searching the green (righthand) area.  Therefore, it is perfectly reasonable that your robot would first of all move to the location of the search area grid."
      ],
      "metadata": {
        "id": "GL5VK6nLiPdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/Search_Boustrophedon.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "SYnR5IIWigQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/observation.png\" align=\"left\"> **Observations:** Regarding the above, a second obvious solution is to program a sequence of straight-line travel and 90° turns - known as a Boustrophedon path.  However, this path has a lot of unncessary travel and rotation.  There will also be an issue of how close each pass of the path should be."
      ],
      "metadata": {
        "id": "azpb7jwAjggr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/Search_LineFollow.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "IGP9WPkhjzeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/observation.png\" align=\"left\"> **Observations:** Regarding the above, it is possible to program the robot to follow the perimeter of the coursework map.  This would make it more probably to find the magnet when it is positioned at the edge of the search area grid. However, it would mean it would be more unlikely to detect the magnet in the central region."
      ],
      "metadata": {
        "id": "mZHnFpGwkQ5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/Search_Ballistic.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "hiegi9tNkIVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/observation.png\" align=\"left\"> **Observations:** Regarding the above, it is also possible to program the robot to simply move forwards and then turn away from the bounding box of the coursework map.  This would likely cause the robot to \"bounce\" around the coursework map, and it would be less likely that the robot would detect the magnet in the corner areas."
      ],
      "metadata": {
        "id": "4QW2mI9LknBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/Search_Efficiency.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "4tLU9r0Ck02Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/observation.png\" align=\"left\"> **Observations:** Regarding the above, it makes sense that if your robot is about to leave the search grid area, it should turn around and go back to the search area.  This would improve the efficiency of the search overall."
      ],
      "metadata": {
        "id": "IBXGvNdHlFZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/paulodowd/EMATM0054_53/main/Images/hypothesis.png\" align=\"left\">**Hypothesise:** The above discussion is not exhaustive.  You are encouraged to develop your own novel solutions to this problem."
      ],
      "metadata": {
        "id": "iJz68lTTmCMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br><br><br><br>\n"
      ],
      "metadata": {
        "id": "uPh6_7BazR7F"
      }
    }
  ]
}